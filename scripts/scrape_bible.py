#!/usr/bin/env python3
"""
åœ£ç»æ•°æ®é‡‡é›†è„šæœ¬
ä» bible.com æŠ“å–ã€Šæ–°æ ‡ç‚¹å’Œåˆæœ¬ã€‹ï¼ˆç¥ç‰ˆï¼‰å…¨éƒ¨ç»æ–‡
"""

import json
import time
import argparse
from pathlib import Path
from playwright.sync_api import sync_playwright

# 66å·ä¹¦å¯¹ç…§è¡¨: (ä¸­æ–‡å, è‹±æ–‡ä»£ç , ç« æ•°)
BIBLE_BOOKS = [
    ("åˆ›ä¸–è®°", "GEN", 50),
    ("å‡ºåŸƒåŠè®°", "EXO", 40),
    ("åˆ©æœªè®°", "LEV", 27),
    ("æ°‘æ•°è®°", "NUM", 36),
    ("ç”³å‘½è®°", "DEU", 34),
    ("çº¦ä¹¦äºšè®°", "JOS", 24),
    ("å£«å¸ˆè®°", "JDG", 21),
    ("è·¯å¾—è®°", "RUT", 4),
    ("æ’’æ¯è€³è®°ä¸Š", "1SA", 31),
    ("æ’’æ¯è€³è®°ä¸‹", "2SA", 24),
    ("åˆ—ç‹çºªä¸Š", "1KI", 22),
    ("åˆ—ç‹çºªä¸‹", "2KI", 25),
    ("å†ä»£å¿—ä¸Š", "1CH", 29),
    ("å†ä»£å¿—ä¸‹", "2CH", 36),
    ("ä»¥æ–¯æ‹‰è®°", "EZR", 10),
    ("å°¼å¸Œç±³è®°", "NEH", 13),
    ("ä»¥æ–¯å¸–è®°", "EST", 10),
    ("çº¦ä¼¯è®°", "JOB", 42),
    ("è¯—ç¯‡", "PSA", 150),
    ("ç®´è¨€", "PRO", 31),
    ("ä¼ é“ä¹¦", "ECC", 12),
    ("é›…æ­Œ", "SNG", 8),
    ("ä»¥èµ›äºšä¹¦", "ISA", 66),
    ("è€¶åˆ©ç±³ä¹¦", "JER", 52),
    ("è€¶åˆ©ç±³å“€æ­Œ", "LAM", 5),
    ("ä»¥è¥¿ç»“ä¹¦", "EZK", 48),
    ("ä½†ä»¥ç†ä¹¦", "DAN", 12),
    ("ä½•è¥¿é˜¿ä¹¦", "HOS", 14),
    ("çº¦ç¥ä¹¦", "JOL", 3),
    ("é˜¿æ‘©å¸ä¹¦", "AMO", 9),
    ("ä¿„å·´åº•äºšä¹¦", "OBA", 1),
    ("çº¦æ‹¿ä¹¦", "JNA", 4),
    ("å¼¥è¿¦ä¹¦", "MIC", 7),
    ("é‚£é¸¿ä¹¦", "NAM", 3),
    ("å“ˆå·´è°·ä¹¦", "HAB", 3),
    ("è¥¿ç•ªé›…ä¹¦", "ZEP", 3),
    ("å“ˆè¯¥ä¹¦", "HAG", 2),
    ("æ’’è¿¦åˆ©äºšä¹¦", "ZEC", 14),
    ("ç›æ‹‰åŸºä¹¦", "MAL", 4),
    # æ–°çº¦
    ("é©¬å¤ªç¦éŸ³", "MAT", 28),
    ("é©¬å¯ç¦éŸ³", "MRK", 16),
    ("è·¯åŠ ç¦éŸ³", "LUK", 24),
    ("çº¦ç¿°ç¦éŸ³", "JHN", 21),
    ("ä½¿å¾’è¡Œä¼ ", "ACT", 28),
    ("ç½—é©¬ä¹¦", "ROM", 16),
    ("å“¥æ—å¤šå‰ä¹¦", "1CO", 16),
    ("å“¥æ—å¤šåä¹¦", "2CO", 13),
    ("åŠ æ‹‰å¤ªä¹¦", "GAL", 6),
    ("ä»¥å¼—æ‰€ä¹¦", "EPH", 6),
    ("è…“ç«‹æ¯”ä¹¦", "PHP", 4),
    ("æ­Œç½—è¥¿ä¹¦", "COL", 4),
    ("å¸–æ’’ç½—å°¼è¿¦å‰ä¹¦", "1TH", 5),
    ("å¸–æ’’ç½—å°¼è¿¦åä¹¦", "2TH", 3),
    ("ææ‘©å¤ªå‰ä¹¦", "1TI", 6),
    ("ææ‘©å¤ªåä¹¦", "2TI", 4),
    ("æå¤šä¹¦", "TIT", 3),
    ("è…“åˆ©é—¨ä¹¦", "PHM", 1),
    ("å¸Œä¼¯æ¥ä¹¦", "HEB", 13),
    ("é›…å„ä¹¦", "JAS", 5),
    ("å½¼å¾—å‰ä¹¦", "1PE", 5),
    ("å½¼å¾—åä¹¦", "2PE", 3),
    ("çº¦ç¿°ä¸€ä¹¦", "1JN", 5),
    ("çº¦ç¿°äºŒä¹¦", "2JN", 1),
    ("çº¦ç¿°ä¸‰ä¹¦", "3JN", 1),
    ("çŠ¹å¤§ä¹¦", "JUD", 1),
    ("å¯ç¤ºå½•", "REV", 22),
]

BASE_URL = "https://www.bible.com/zh-CN/bible/48/{book}.{chapter}.CUNPSS-%E7%A5%9E"


def extract_verses(page):
    """ä»å½“å‰é¡µé¢æå–æ‰€æœ‰ç»æ–‡"""
    return page.evaluate("""
    () => {
        const verses = [];
        // Select both labels and content spans in order of appearance
        // YouVersion uses obfuscated classes like ChapterContent_label__... and ChapterContent_content__...
        const elements = document.querySelectorAll('span[class*="ChapterContent_label"], span[class*="ChapterContent_content"]');
        
        let currentVerseNum = 0;
        let currentText = "";

        elements.forEach(el => {
            const className = el.className;
            const text = el.innerText.trim();
            
            if (className.includes("ChapterContent_label")) {
                // If we have accumulated text for a previous verse, push it
                if (currentVerseNum > 0 && currentText) {
                    verses.push({ verse: currentVerseNum, text: currentText });
                    currentText = "";
                }
                currentVerseNum = parseInt(text);
            } else if (className.includes("ChapterContent_content")) {
                // Append text (some verses are split across multiple spans)
                currentText += text;
            }
        });
        
        // Push the last verse
        if (currentVerseNum > 0 && currentText) {
            verses.push({ verse: currentVerseNum, text: currentText });
        }
        
        return verses;
    }
    """)


def scrape_chapter(page, book_code: str, chapter: int) -> list:
    """æŠ“å–å•ç« å†…å®¹"""
    url = BASE_URL.format(book=book_code, chapter=chapter)
    
    max_retries = 5
    for attempt in range(max_retries):
        try:
            # éšæœºå»¶è¿Ÿï¼Œæ¨¡æ‹Ÿäººç±»
            time.sleep(1 + (attempt * 2)) 
            page.goto(url, wait_until="domcontentloaded", timeout=60000)
            # wait networkidle separately to avoid timeout on tracking scripts
            try:
                page.wait_for_load_state("networkidle", timeout=5000)
            except:
                pass # networkidle is strict, sometimes irrelevant
            break
        except Exception as e:
            if attempt < max_retries - 1:
                wait_time = 2 ** (attempt + 1)
                print(f"âš ï¸ è®¿é—®å¤±è´¥ (å°è¯• {attempt+1}/{max_retries}): {e}. ç­‰å¾… {wait_time}s...")
                time.sleep(wait_time)
            else:
                print(f"âŒ æœ€ç»ˆå¤±è´¥: {url}")
                raise e
    
    verses = extract_verses(page)
    print(f"  ç¬¬ {chapter} ç« : {len(verses)} èŠ‚")
    return verses


def scrape_book(browser, book_name: str, book_code: str, chapter_count: int, output_dir: Path):
    output_file = output_dir / f"{book_code}.json"
    if output_file.exists():
        print(f"â­ï¸ å·²å­˜åœ¨ï¼Œè·³è¿‡: {book_name}")
        return
        
    print(f"\nğŸ“– æ­£åœ¨é‡‡é›†: {book_name} ({book_code}) - å…± {chapter_count} ç« ")
    
    page = browser.new_page()
    book_data = {
        "name": book_name,
        "code": book_code,
        "chapter_count": chapter_count,
        "chapters": []
    }
    
    for ch in range(1, chapter_count + 1):
        verses = scrape_chapter(page, book_code, ch)
        book_data["chapters"].append({
            "chapter": ch,
            "verses": verses
        })
        time.sleep(0.5)  # é¿å…è¯·æ±‚è¿‡å¿«
    
    page.close()
    
    # ä¿å­˜åˆ°æ–‡ä»¶
    output_file = output_dir / f"{book_code}.json"
    with open(output_file, "w", encoding="utf-8") as f:
        json.dump(book_data, f, ensure_ascii=False, indent=2)
    
    print(f"âœ… {book_name} å·²ä¿å­˜åˆ° {output_file}")
    return book_data


def main():
    parser = argparse.ArgumentParser(description="åœ£ç»æ•°æ®é‡‡é›†è„šæœ¬")
    parser.add_argument("--book", type=str, help="æŒ‡å®šè¦é‡‡é›†çš„ä¹¦å·ä»£ç  (å¦‚ MAT)")
    parser.add_argument("--all", action="store_true", help="é‡‡é›†å…¨éƒ¨ 66 å·")
    parser.add_argument("--output", type=str, default="data/raw", help="è¾“å‡ºç›®å½•")
    args = parser.parse_args()
    
    output_dir = Path(args.output)
    output_dir.mkdir(parents=True, exist_ok=True)
    
    # ç¡®å®šè¦é‡‡é›†çš„ä¹¦å·
    if args.book:
        books_to_scrape = [(n, c, ch) for n, c, ch in BIBLE_BOOKS if c == args.book.upper()]
        if not books_to_scrape:
            print(f"âŒ æœªæ‰¾åˆ°ä¹¦å·ä»£ç : {args.book}")
            return
    elif args.all:
        books_to_scrape = BIBLE_BOOKS
    else:
        # é»˜è®¤åªé‡‡é›†é©¬å¤ªç¦éŸ³ä½œä¸ºæµ‹è¯•
        books_to_scrape = [("é©¬å¤ªç¦éŸ³", "MAT", 28)]
    
    print(f"ğŸš€ å¼€å§‹é‡‡é›† {len(books_to_scrape)} å·ä¹¦...")
    
    with sync_playwright() as p:
        browser = p.chromium.launch(headless=True)
        
        for name, code, chapters in books_to_scrape:
            scrape_book(browser, name, code, chapters, output_dir)
        
        browser.close()
    
    print("\nğŸ‰ é‡‡é›†å®Œæˆ!")


if __name__ == "__main__":
    main()
